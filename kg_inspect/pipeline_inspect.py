# kg_inspect/pipeline/pipeline_inspect.py

from __future__ import annotations

from typing import List, Optional, Dict, Any

from rich.console import Console
from rich.panel import Panel

from lightrag.base import QueryParam

from kg_inspect.kg_inspect import KGInspect
from kg_inspect.cnn_inspect import CNNInspect
from kg_inspect.utils.prompt import Prompt
console = Console()


class InspectionPipeline:
    """
    Orchestrator k·∫øt h·ª£p:
      - CNNInspect (ConvNeXt + CutPaste) cho ·∫£nh
      - KGInspect (LightRAG + VLM) cho RAG + reasoning

    Lu·ªìng:
      - N·∫øu kh√¥ng c√≥ ·∫£nh:
          ‚Üí G·ªçi th·∫≥ng rag.aquery(user_query, ...)
      - N·∫øu c√≥ ·∫£nh:
          ‚Üí M·ªói ·∫£nh ƒëi qua CNNInspect
          ‚Üí Prompt sinh th√™m text "This {object} is (not) defective."
          ‚Üí Gh√©p v√†o c√¢u h·ªèi ng∆∞·ªùi d√πng (augmented_query)
          ‚Üí G·ªçi rag.aquery(augmented_query, images=...) ƒë·ªÉ VLM x·ª≠ l√Ω
    """

    def __init__(
        self,
        rag: KGInspect,
        cnn: Optional[CNNInspect] = None,
    ) -> None:
        self.rag = rag
        self.cnn = cnn or CNNInspect()

    
    async def _inspect_images(
        self, image_paths: List[str]
    ) -> Dict[str, List[Any]]:
        """
        Ch·∫°y CNNInspect cho t·ª´ng ·∫£nh v√† gom k·∫øt qu·∫£ th√†nh c√°c list song song.

        Returns:
            {
                "paths": [...],
                "labels": [...],
                "anomaly_flags": [...],
                "confidences": [...],
                "scores": [...],
                "thresholds": [...],
            }
        """
        labels: List[str] = []
        anomaly_flags: List[bool] = []
        confidences: List[float] = []
        scores: List[Optional[float]] = []
        thresholds: List[Optional[float]] = []

        for path in image_paths:
            out = await self.cnn.run(path)
            conv = out.get("convnext", {}) or {}
            cp = out.get("cutpaste", {}) or {}

            label = conv.get("label") or "object"
            confidence = float(conv.get("confidence", 0.0))
            is_anomaly = bool(cp.get("is_anomaly", False))
            score = cp.get("score")
            threshold = cp.get("threshold")

            labels.append(label)
            anomaly_flags.append(is_anomaly)
            confidences.append(confidence)
            scores.append(float(score) if score is not None else None)
            thresholds.append(float(threshold) if threshold is not None else None)

        return {
            "paths": image_paths,
            "labels": labels,
            "anomaly_flags": anomaly_flags,
            "confidences": confidences,
            "scores": scores,
            "thresholds": thresholds,
        }

    
    async def run(
        self,
        user_query: str,
        images: Optional[List[str]] = None,
        system_prompt: Optional[str] = None,
        mode: str = "hybrid",
        query_param: Optional[QueryParam] = None,
    ) -> Dict[str, Any]:
        """
        ƒêi·ªÉm v√†o ch√≠nh c·ªßa pipeline.

        Args:
            user_query: c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng (text).
            images: list ƒë∆∞·ªùng d·∫´n ·∫£nh (n·∫øu c√≥).
            system_prompt: system prompt cho VLM/RAG.
            mode: mode query c·ªßa LightRAG (m·∫∑c ƒë·ªãnh: "hybrid").
            query_param: n·∫øu mu·ªën custom th√™m, c√≥ th·ªÉ truy·ªÅn; n·∫øu None s·∫Ω t·∫°o m·ªõi.

        Returns:
            dict: k·∫øt qu·∫£ th√¥ t·ª´ rag.aquery (raw_data + llm_response wrapper c·ªßa b·∫°n).
        """

        if query_param is None:
            query_param = QueryParam(
                mode=mode,
                stream=False,        # b·∫°n c√≥ th·ªÉ b·∫≠t True n·∫øu mu·ªën stream
                enable_rerank=False, # tu·ª≥ config
            )

        # ======= Tr∆∞·ªùng h·ª£p KH√îNG c√≥ ·∫£nh =======
        if not images:
            console.print(
                Panel(
                    "[bold cyan]No images provided.[/bold cyan] "
                    "Running pure text RAG query.",
                    title="üîç InspectionPipeline",
                    border_style="cyan",
                )
            )
            return await self.rag.aquery(
                user_query, param=query_param, system_prompt=system_prompt
            )

        console.print(
            Panel(
                f"[bold]Images provided:[/bold] {len(images)}\n"
                f"- Will run ConvNeXt + CutPaste + RAG/VLM.",
                title="üß™ Visual + Text Inspection",
                border_style="green",
            )
        )

        inspection = await self._inspect_images(images)

        visual_context = Prompt.build_visual_context(
            image_paths=inspection["paths"],
            labels=inspection["labels"],
            anomaly_flags=inspection["anomaly_flags"],
        )

        console.print(
            Panel(
                f"[bold]Visual context:[/bold]\n{visual_context}",
                title="üßø CNNInspect Summary",
                border_style="magenta",
            )
        )

        # Gh√©p c√¢u h·ªèi ng∆∞·ªùi d√πng v·ªõi context t·ª´ ·∫£nh b·∫±ng Prompt
        augmented_query = Prompt.build_augmented_query(
            user_query=user_query,
            visual_context=visual_context,
        )

        # G·ªçi VLM + RAG
        result = await self.rag.aquery(
            augmented_query,
            images=images,             # VLM v·∫´n nh√¨n ƒë∆∞·ª£c ·∫£nh
            param=query_param,
            system_prompt=system_prompt,
        )

        if isinstance(result, dict):
            result.setdefault("inspection_meta", {})
            result["inspection_meta"]["images"] = images
            result["inspection_meta"]["visual_context"] = visual_context
            result["inspection_meta"]["inspection"] = inspection

        return result
