{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44861f3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T14:35:30.521996Z",
     "iopub.status.busy": "2025-10-23T14:35:30.521759Z",
     "iopub.status.idle": "2025-10-23T14:35:41.931837Z",
     "shell.execute_reply": "2025-10-23T14:35:41.931098Z"
    },
    "papermill": {
     "duration": 11.415093,
     "end_time": "2025-10-23T14:35:41.933499",
     "exception": false,
     "start_time": "2025-10-23T14:35:30.518406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "619e972c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T14:35:41.939297Z",
     "iopub.status.busy": "2025-10-23T14:35:41.938486Z",
     "iopub.status.idle": "2025-10-23T14:35:42.029275Z",
     "shell.execute_reply": "2025-10-23T14:35:42.028519Z"
    },
    "papermill": {
     "duration": 0.094461,
     "end_time": "2025-10-23T14:35:42.030416",
     "exception": false,
     "start_time": "2025-10-23T14:35:41.935955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "CLASS_NUMBER = 2\n",
    "channels = 3\n",
    "img_height = 64\n",
    "img_width = 64\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "datasetDir = r'/kaggle/input/trees-in-satellite-imagery'  # adjust path\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "834cd9e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T14:35:42.035843Z",
     "iopub.status.busy": "2025-10-23T14:35:42.035185Z",
     "iopub.status.idle": "2025-10-23T14:35:42.100176Z",
     "shell.execute_reply": "2025-10-23T14:35:42.099406Z"
    },
    "papermill": {
     "duration": 0.068899,
     "end_time": "2025-10-23T14:35:42.101509",
     "exception": false,
     "start_time": "2025-10-23T14:35:42.032610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/kg-inspect-dataset-2/train_formatted (1).csv\")\n",
    "valid = pd.read_csv(\"/kaggle/input/kg-inspect-dataset-2/valid_formatted (1).csv\")\n",
    "test = pd.read_csv(\"/kaggle/input/kg-inspect-dataset-2/test_formatted (1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4eca407",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T14:35:42.106761Z",
     "iopub.status.busy": "2025-10-23T14:35:42.106325Z",
     "iopub.status.idle": "2025-10-23T14:35:42.125811Z",
     "shell.execute_reply": "2025-10-23T14:35:42.125096Z"
    },
    "papermill": {
     "duration": 0.02327,
     "end_time": "2025-10-23T14:35:42.126962",
     "exception": false,
     "start_time": "2025-10-23T14:35:42.103692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/kaggle/input/mvtec-ad/bottle/train/good/173.png</td>\n",
       "      <td>bottle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/kaggle/input/mvtec-ad/bottle/train/good/043.png</td>\n",
       "      <td>bottle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/kaggle/input/mvtec-ad/bottle/train/good/038.png</td>\n",
       "      <td>bottle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/kaggle/input/mvtec-ad/bottle/train/good/069.png</td>\n",
       "      <td>bottle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/kaggle/input/mvtec-ad/bottle/train/good/083.png</td>\n",
       "      <td>bottle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Image   Label\n",
       "0  /kaggle/input/mvtec-ad/bottle/train/good/173.png  bottle\n",
       "1  /kaggle/input/mvtec-ad/bottle/train/good/043.png  bottle\n",
       "2  /kaggle/input/mvtec-ad/bottle/train/good/038.png  bottle\n",
       "3  /kaggle/input/mvtec-ad/bottle/train/good/069.png  bottle\n",
       "4  /kaggle/input/mvtec-ad/bottle/train/good/083.png  bottle"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8d4754f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T14:35:42.132720Z",
     "iopub.status.busy": "2025-10-23T14:35:42.132491Z",
     "iopub.status.idle": "2025-10-23T14:35:42.140763Z",
     "shell.execute_reply": "2025-10-23T14:35:42.140198Z"
    },
    "papermill": {
     "duration": 0.012475,
     "end_time": "2025-10-23T14:35:42.141774",
     "exception": false,
     "start_time": "2025-10-23T14:35:42.129299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CSVImageDataset(Dataset):\n",
    "    def __init__(self, df, label2idx, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.label2idx = label2idx\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = str(row[\"Image\"])\n",
    "        label_name = str(row[\"Label\"])\n",
    "        label = self.label2idx[label_name]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "def make_label_mapping(train_df):\n",
    "    classes = sorted(train_df[\"Label\"].astype(str).unique())\n",
    "    label2idx = {c: i for i, c in enumerate(classes)}\n",
    "    idx2label = {i: c for c, i in label2idx.items()}\n",
    "    return label2idx, idx2label\n",
    "\n",
    "def get_basic_loaders(train_df, val_df, test_df, img_size=224, batch_size=64, device='cuda'):\n",
    "    \"\"\"\n",
    "    Loaders cơ bản: chỉ resize + tensor, không augment\n",
    "    \"\"\"\n",
    "    label2idx, idx2label = make_label_mapping(train_df)\n",
    "\n",
    "    basic_tf = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),   # không Normalize để load nhanh\n",
    "    ])\n",
    "\n",
    "    train_ds = CSVImageDataset(train_df, label2idx, transform=basic_tf)\n",
    "    val_ds   = CSVImageDataset(val_df,   label2idx, transform=basic_tf)\n",
    "    test_ds  = CSVImageDataset(test_df,  label2idx, transform=basic_tf)\n",
    "\n",
    "    num_workers = min(4, os.cpu_count() or 2)\n",
    "    pin = (device == \"cuda\")\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=num_workers, pin_memory=pin)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False,\n",
    "                              num_workers=num_workers, pin_memory=pin)\n",
    "    test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False,\n",
    "                              num_workers=num_workers, pin_memory=pin)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, label2idx, idx2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c341c4e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T14:35:42.146908Z",
     "iopub.status.busy": "2025-10-23T14:35:42.146691Z",
     "iopub.status.idle": "2025-10-23T14:35:42.156380Z",
     "shell.execute_reply": "2025-10-23T14:35:42.155717Z"
    },
    "papermill": {
     "duration": 0.013429,
     "end_time": "2025-10-23T14:35:42.157421",
     "exception": false,
     "start_time": "2025-10-23T14:35:42.143992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lớp: {'bottle': 0, 'cable': 1, 'candle': 2, 'capsule': 3, 'capsules': 4, 'carpet': 5, 'cashew': 6, 'chewinggum': 7, 'fryum': 8, 'grid': 9, 'hazelnut': 10, 'leather': 11, 'macaroni1': 12, 'macaroni2': 13, 'metal_nut': 14, 'pcb1': 15, 'pcb2': 16, 'pcb3': 17, 'pcb4': 18, 'pill': 19, 'pipe_fryum': 20, 'screw': 21, 'tile': 22, 'toothbrush': 23, 'transistor': 24, 'wood': 25, 'zipper': 26}\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, label2idx, idx2label = get_basic_loaders(\n",
    "    train, valid, test,\n",
    "    img_size=64,     # hoặc 224 nếu bạn muốn giữ chuẩn ConvNeXt\n",
    "    batch_size=64,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "num_classes = len(label2idx)\n",
    "print(\"Lớp:\", label2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b354e45c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T14:35:42.162240Z",
     "iopub.status.busy": "2025-10-23T14:35:42.162071Z",
     "iopub.status.idle": "2025-10-23T14:35:43.707827Z",
     "shell.execute_reply": "2025-10-23T14:35:43.707006Z"
    },
    "papermill": {
     "duration": 1.549603,
     "end_time": "2025-10-23T14:35:43.709106",
     "exception": false,
     "start_time": "2025-10-23T14:35:42.159503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ConvNeXt_Tiny_Weights.IMAGENET1K_V1`. You can also use `weights=ConvNeXt_Tiny_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/convnext_tiny-983f1562.pth\" to /root/.cache/torch/hub/checkpoints/convnext_tiny-983f1562.pth\n",
      "100%|██████████| 109M/109M [00:00<00:00, 190MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torchvision convnext_tiny\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model = models.convnext_tiny(pretrained=True)\n",
    "    print('Using torchvision convnext_tiny')\n",
    "    # Freeze the backbone (features)\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    # Replace classifier head with pooling + flatten + layernorm + linear\n",
    "    in_features = model.classifier[-1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.AdaptiveAvgPool2d((1,1)),\n",
    "        nn.Flatten(1),\n",
    "        nn.LayerNorm(in_features),\n",
    "        nn.Linear(in_features, num_classes)\n",
    "    )\n",
    "except Exception as e:\n",
    "    print('torchvision convnext_tiny not available:', e)\n",
    "    try:\n",
    "        import timm\n",
    "        model = timm.create_model('convnext_tiny', pretrained=True)\n",
    "        print('Using timm convnext_tiny')\n",
    "        # Freeze the backbone for timm\n",
    "        for name, param in model.named_parameters():\n",
    "            if 'head' not in name and 'classifier' not in name:\n",
    "                param.requires_grad = False\n",
    "        model.reset_classifier(num_classes=num_classes)\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Neither torchvision convnext_tiny nor timm is available. Install timm with: pip install timm\")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e106aa9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T14:35:43.715488Z",
     "iopub.status.busy": "2025-10-23T14:35:43.715213Z",
     "iopub.status.idle": "2025-10-23T15:14:14.643558Z",
     "shell.execute_reply": "2025-10-23T15:14:14.642589Z"
    },
    "papermill": {
     "duration": 2310.935526,
     "end_time": "2025-10-23T15:14:14.647557",
     "exception": false,
     "start_time": "2025-10-23T14:35:43.712031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - train_loss: 1.3047 train_acc: 0.7934 val_loss: 0.4190 val_acc: 0.9702\n",
      "Epoch 2/20 - train_loss: 0.1934 train_acc: 0.9962 val_loss: 0.1497 val_acc: 0.9903\n",
      "Epoch 3/20 - train_loss: 0.0811 train_acc: 0.9984 val_loss: 0.0918 val_acc: 0.9944\n",
      "Epoch 4/20 - train_loss: 0.0490 train_acc: 0.9985 val_loss: 0.0673 val_acc: 0.9951\n",
      "Epoch 5/20 - train_loss: 0.0343 train_acc: 0.9983 val_loss: 0.0524 val_acc: 0.9965\n",
      "Epoch 6/20 - train_loss: 0.0236 train_acc: 0.9995 val_loss: 0.0456 val_acc: 0.9965\n",
      "Epoch 7/20 - train_loss: 0.0193 train_acc: 0.9989 val_loss: 0.0389 val_acc: 0.9972\n",
      "Epoch 8/20 - train_loss: 0.0155 train_acc: 0.9991 val_loss: 0.0348 val_acc: 0.9972\n",
      "Epoch 9/20 - train_loss: 0.0127 train_acc: 0.9995 val_loss: 0.0315 val_acc: 0.9972\n",
      "Epoch 10/20 - train_loss: 0.0097 train_acc: 0.9995 val_loss: 0.0287 val_acc: 0.9972\n",
      "Epoch 11/20 - train_loss: 0.0085 train_acc: 0.9995 val_loss: 0.0264 val_acc: 0.9972\n",
      "Epoch 12/20 - train_loss: 0.0072 train_acc: 0.9997 val_loss: 0.0250 val_acc: 0.9972\n",
      "Epoch 13/20 - train_loss: 0.0073 train_acc: 0.9991 val_loss: 0.0228 val_acc: 0.9972\n",
      "Epoch 14/20 - train_loss: 0.0055 train_acc: 0.9997 val_loss: 0.0219 val_acc: 0.9972\n",
      "Epoch 15/20 - train_loss: 0.0047 train_acc: 0.9997 val_loss: 0.0212 val_acc: 0.9972\n",
      "Epoch 16/20 - train_loss: 0.0043 train_acc: 0.9998 val_loss: 0.0204 val_acc: 0.9972\n",
      "Epoch 17/20 - train_loss: 0.0038 train_acc: 0.9998 val_loss: 0.0188 val_acc: 0.9972\n",
      "Epoch 18/20 - train_loss: 0.0033 train_acc: 0.9997 val_loss: 0.0186 val_acc: 0.9972\n",
      "Epoch 19/20 - train_loss: 0.0033 train_acc: 0.9997 val_loss: 0.0171 val_acc: 0.9972\n",
      "Epoch 20/20 - train_loss: 0.0026 train_acc: 0.9998 val_loss: 0.0156 val_acc: 0.9972\n"
     ]
    }
   ],
   "source": [
    "# Training loop (simple)\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # train\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_acc.append(epoch_acc)\n",
    "\n",
    "    # val\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    val_loss = running_loss / total if total>0 else 0\n",
    "    val_accuracy = correct / total if total>0 else 0\n",
    "    val_losses.append(val_loss)\n",
    "    val_acc.append(val_accuracy)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs} - train_loss: {epoch_loss:.4f} train_acc: {epoch_acc:.4f} val_loss: {val_loss:.4f} val_acc: {val_accuracy:.4f}')\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), 'convnext_tiny_kg_inspect.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc882e72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T15:14:14.656241Z",
     "iopub.status.busy": "2025-10-23T15:14:14.655784Z",
     "iopub.status.idle": "2025-10-23T15:14:14.662270Z",
     "shell.execute_reply": "2025-10-23T15:14:14.661536Z"
    },
    "papermill": {
     "duration": 0.012349,
     "end_time": "2025-10-23T15:14:14.663434",
     "exception": false,
     "start_time": "2025-10-23T15:14:14.651085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hàm evaluate dùng chung cho val/test\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs) \n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            all_preds.append(preds.detach().cpu().numpy())\n",
    "            all_labels.append(labels.detach().cpu().numpy())\n",
    "\n",
    "    avg_loss = running_loss / total if total > 0 else 0.0\n",
    "    acc = correct / total if total > 0 else 0.0\n",
    "    all_preds = np.concatenate(all_preds) if all_preds else np.array([])\n",
    "    all_labels = np.concatenate(all_labels) if all_labels else np.array([])\n",
    "    return avg_loss, acc, all_preds, all_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7fd350f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T15:14:14.671685Z",
     "iopub.status.busy": "2025-10-23T15:14:14.671050Z",
     "iopub.status.idle": "2025-10-23T15:14:33.556870Z",
     "shell.execute_reply": "2025-10-23T15:14:33.555906Z"
    },
    "papermill": {
     "duration": 18.891435,
     "end_time": "2025-10-23T15:14:33.558284",
     "exception": false,
     "start_time": "2025-10-23T15:14:14.666849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] loss: 0.0166  acc: 0.9987\n",
      "\n",
      "Classification report (test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        42\n",
      "           1     1.0000    1.0000    1.0000        76\n",
      "           2     1.0000    1.0000    1.0000        50\n",
      "           3     1.0000    1.0000    1.0000        68\n",
      "           4     1.0000    1.0000    1.0000        50\n",
      "           5     1.0000    1.0000    1.0000        61\n",
      "           6     0.9804    1.0000    0.9901        50\n",
      "           7     1.0000    1.0000    1.0000        50\n",
      "           8     1.0000    1.0000    1.0000        50\n",
      "           9     1.0000    1.0000    1.0000        41\n",
      "          10     1.0000    0.9821    0.9910        56\n",
      "          11     1.0000    0.9844    0.9921        64\n",
      "          12     1.0000    1.0000    1.0000        50\n",
      "          13     1.0000    1.0000    1.0000        50\n",
      "          14     1.0000    1.0000    1.0000        59\n",
      "          15     1.0000    1.0000    1.0000        50\n",
      "          16     1.0000    1.0000    1.0000        50\n",
      "          17     1.0000    1.0000    1.0000        50\n",
      "          18     1.0000    1.0000    1.0000        50\n",
      "          19     1.0000    1.0000    1.0000        86\n",
      "          20     1.0000    1.0000    1.0000        50\n",
      "          21     0.9880    1.0000    0.9939        82\n",
      "          22     1.0000    1.0000    1.0000        60\n",
      "          23     1.0000    1.0000    1.0000        21\n",
      "          24     1.0000    1.0000    1.0000        50\n",
      "          25     1.0000    1.0000    1.0000        41\n",
      "          26     1.0000    1.0000    1.0000        77\n",
      "\n",
      "    accuracy                         0.9987      1484\n",
      "   macro avg     0.9988    0.9988    0.9988      1484\n",
      "weighted avg     0.9987    0.9987    0.9987      1484\n",
      "\n",
      "Confusion matrix (test):\n",
      "[[42  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0 76  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0 50  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0 68  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0 50  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0 61  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0 50  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0 50  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 50  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 41  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 55  0  0  0  0  0  0  0  0  0  0  1  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0 63  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 50  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 50  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 59  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 50  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 50  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 50  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 50  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 86  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 50  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 82  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 60  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 21\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  50  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0 41  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0 77]]\n"
     ]
    }
   ],
   "source": [
    "# ===== Sau khi train xong, đánh giá trên test =====\n",
    "test_loss, test_acc, y_pred, y_true = evaluate(model, test_loader, criterion, device)\n",
    "print(f\"[TEST] loss: {test_loss:.4f}  acc: {test_acc:.4f}\")\n",
    "\n",
    "# (Tuỳ chọn) In báo cáo chi tiết nếu có sklearn\n",
    "try:\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    # Nếu bạn có idx2label, truyền vào đây để tên lớp đẹp hơn:\n",
    "    # target_names = [idx2label[i] for i in range(len(idx2label))]\n",
    "    # Nếu không có, đặt None để sklearn tự dùng chỉ số lớp\n",
    "    target_names = None\n",
    "\n",
    "    print(\"\\nClassification report (test):\")\n",
    "    print(classification_report(y_true, y_pred, target_names=target_names, digits=4))\n",
    "\n",
    "    print(\"Confusion matrix (test):\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "except Exception as e:\n",
    "    print(\"Không thể in classification report/confusion matrix (thiếu sklearn?):\", e)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1946896,
     "sourceId": 3209332,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5929630,
     "sourceId": 9697599,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8556384,
     "sourceId": 13477584,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2349.342309,
   "end_time": "2025-10-23T15:14:35.949836",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-23T14:35:26.607527",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
